# Copyright 2021 The Fuchsia Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

import("//build/testing/perf/test.gni")
import("gvisor_tests.gni")

group("tests") {
  testonly = true
  deps = []

  if (!is_asan) {
    deps += [
      ":starnix_gvisor_benchmarks",
      ":starnix_gvisor_tests",
    ]
    if (data_filesystem_format == "fxfs") {
      deps += [ ":starnix_gvisor_tests_on_fxfs" ]
    }
  }
}

gvisor_benchmarks = [
  "clock_getres",
  "clock_gettime",
  "death",
  "dup",
  "epoll",
  "fork",
  "futex",
  "getdents",
  "getpid",
  "gettid",
  "mapping",
  "open",
  "open_read_close",
  "pipe",
  "poll",
  "randread",
  "read",
  "sched_yield",
  "select",
  "send_recv",
  "seqwrite",
  "signal",
  "sleep",
  "stat",
  "unlink",
  "write",
]

test_runfiles = [
  "exec_assert_closed_workload",
  "exec_basic_workload",
  "exec_proc_exe_workload",
  "exec_state_workload",
  "priority_execve",
]

# These runfiles are binaries used by the test binaries. They need to be placed in the specific
# location that the test binaries expect them.
foreach(resource_name, test_runfiles) {
  resource(resource_name) {
    sources = [ "${gvisor_prebuilt_directory}/stripped/${resource_name}" ]
    outputs = [ "data/tests/runfiles/test/syscalls/linux/${resource_name}" ]
  }
}

# The exit script is a runfile that needs to be renamed explicitly.
resource("exit_script") {
  sources = [ "${gvisor_prebuilt_directory}/stripped/exit_script.sh" ]
  outputs = [ "data/tests/runfiles/test/syscalls/linux/exit_script" ]
}

group("gvisor_runfiles") {
  deps = [ ":exit_script" ]
  foreach(runfile_name, test_runfiles) {
    deps += [ ":${runfile_name}" ]
  }
}

foreach(benchmark_name, gvisor_benchmarks) {
  name = "${benchmark_name}_benchmark"
  gvisor_test_component(name) {
    is_benchmark = true
    run_as_root = false
  }
}

# GVisor tests with the default settings.
gvisor_tests_package("starnix_gvisor_tests") {
}

# GVisor tests with persistent storage on fxfs.
gvisor_tests_package("starnix_gvisor_tests_on_fxfs") {
  expectations = "expectations/using_fxfs_test.json5"
  if (!starnix_unified_aspace) {
    expectations = "expectations/using_fxfs_test_no_unified_aspace.json5"
  }
  use_persistent_storage = true
  suffix = "_use_persistent_storage"
}

fuchsia_test_package("starnix_gvisor_benchmarks") {
  deps = [ ":gvisor_runfiles" ]

  test_components = []

  foreach(benchmark_name, gvisor_benchmarks) {
    test_components += [ ":${benchmark_name}_benchmark" ]
  }

  subpackages = starnix_test_subpackages +
                [ "//src/starnix/containers/debian:debian_package" ]

  # Set environments to none so infra doesn't run these benchmarks.
  # These benchmarks are run as a part of:
  # //src/tests/end_to_end/perf/test/starnix_gvisor_benchmarks_test.dart
  test_specs = {
    environments = []
  }
}

all_benchmark_targets = []
foreach(benchmark_name, gvisor_benchmarks) {
  # The "starnix_host_benchmark_gvisor_" prefix is useful for running all benchmarks with `fx test`.
  name = "starnix_host_benchmark_gvisor_${benchmark_name}"
  fuchsia_component_perf_test(name) {
    package = ":starnix_gvisor_benchmarks"
    component_name = "${benchmark_name}_benchmark"
    expected_metric_names_filepath = "//src/tests/end_to_end/perf/expected_metric_names/fuchsia.starnix.gvisor_benchmarks.${benchmark_name}.txt"

    # TODO(b/275745984): Remove per-benchmark filters.
    if (benchmark_name == "fork") {
      test_component_args = [ "--benchmark_filter_internal=-BM_ThreadSwitch" ]
    } else if (benchmark_name == "gettid") {
      test_component_args = [ string_join("",
                                          [
                                            "--benchmark_filter_internal=-",
                                            "BM_Gettid/real_time/threads:1024|",
                                            "BM_Gettid/real_time/threads:2048|",
                                            "BM_Gettid/real_time/threads:4000",
                                          ]) ]
    } else if (benchmark_name == "send_recv") {
      test_component_args = [ "--benchmark_filter_internal=-BM_SendmsgTCP*" ]
    } else {
      test_component_args = [ "--benchmark_filter_internal=all" ]
    }
    test_type = "starnix"
  }

  all_benchmark_targets += [ ":${name}" ]
}

group("benchmarks") {
  testonly = true
  if (!is_asan) {
    deps = all_benchmark_targets
  }
}
